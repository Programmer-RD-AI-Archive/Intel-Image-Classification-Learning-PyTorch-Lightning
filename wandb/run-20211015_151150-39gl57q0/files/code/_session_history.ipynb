{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ce8ef7b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning import Trainer\n",
    "import wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dc0d8cc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader,Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4e29c8e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataSet_Loader(DataLoader):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.labels = {}\n",
    "        self.labels_r = {}\n",
    "        self.idx = 0\n",
    "        self.data = []\n",
    "        for label in tqdm(os.listdir('./data/')):\n",
    "            self.idx += 1\n",
    "            self.labels[label] = idx\n",
    "            self.labels_r[idx] = label\n",
    "        for folder in tqdm(os.listdir('./data/')):\n",
    "            for file in os.listdir(f'./data/{folder}/'):\n",
    "                img = cv2.imread(f'./data/{folder}/{file}')\n",
    "                img = cv2.resize(img,(56,56))\n",
    "                img = img / 255.0\n",
    "                self.data.append([\n",
    "                    img,\n",
    "                    np.eye(labels[folder],len(labels))[labels[folder]-1]\n",
    "                ])\n",
    "        np.random.shuffle(self.data)\n",
    "        self.X = []\n",
    "        self.y = []\n",
    "        for d in self.data:\n",
    "            self.X.append(d[0])\n",
    "            self.y.append(d[1])\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "    \n",
    "    def __getitem__(self,idx):\n",
    "        return self.X[idx],self.y[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bd07625c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning import Trainer\n",
    "import wandb\n",
    "PROJECT_NAME = 'Intel-Image-Classification-Learning-PyTorch-Lightning'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1869ad2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader,Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "af835fc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 0\n",
    "labels = {}\n",
    "labels_r = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "44c595bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "for label in tqdm(os.listdir('./data/')):\n",
    "    idx += 1\n",
    "    labels[label] = idx\n",
    "    labels_r[idx] = label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "71fe7fad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning import Trainer\n",
    "from tqdm import tqdm\n",
    "import wandb\n",
    "PROJECT_NAME = 'Intel-Image-Classification-Learning-PyTorch-Lightning'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8b7be14f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader,Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fccf802e",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 0\n",
    "labels = {}\n",
    "labels_r = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a24ddaf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "for label in tqdm(os.listdir('./data/')):\n",
    "    idx += 1\n",
    "    labels[label] = idx\n",
    "    labels_r[idx] = label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4f57a852",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning import Trainer\n",
    "from tqdm import tqdm\n",
    "import wandb,ps\n",
    "PROJECT_NAME = 'Intel-Image-Classification-Learning-PyTorch-Lightning'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8d676e11",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader,Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "72285216",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning import Trainer\n",
    "from tqdm import tqdm\n",
    "import wandb,os\n",
    "PROJECT_NAME = 'Intel-Image-Classification-Learning-PyTorch-Lightning'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c40fb5f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader,Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bd123300",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 0\n",
    "labels = {}\n",
    "labels_r = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "65258b3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for label in tqdm(os.listdir('./data/')):\n",
    "    idx += 1\n",
    "    labels[label] = idx\n",
    "    labels_r[idx] = label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "16e89d66",
   "metadata": {},
   "outputs": [],
   "source": [
    "for label in tqdm(os.listdir('./data/')):\n",
    "    idx += 1\n",
    "    labels[label] = idx\n",
    "    labels_r[idx] = label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9e7400dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = MSELoss()\n",
    "class Model(pl.LightningModule):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.activation = ReLU()\n",
    "        self.linear1 = Linear(3*56*56,256)\n",
    "        self.linear2 = Linear(256,512)\n",
    "        self.linear3 = Linear(512,1024)\n",
    "        self.output = Linear(1024,len(labels))\n",
    "    \n",
    "    def forward(self,X):\n",
    "        preds = self.linear1(X)\n",
    "        preds = self.activation(self.linear2(preds))\n",
    "        preds = self.activation(self.linear3(preds))\n",
    "        preds = self.output(preds)\n",
    "        return preds\n",
    "    \n",
    "    def training_step(self,batch,batch_idx):\n",
    "        images,labels = batch\n",
    "        images = images.view(-1,56*56*3)\n",
    "        outputs = self(images)\n",
    "        loss = criterion(outputs,labels)\n",
    "        wandb.log({'Loss':loss.item()})\n",
    "        return {'train_loss':loss}\n",
    "    \n",
    "    def train_dataloader(self):\n",
    "        train_data = DataSet_Loader()\n",
    "        dataset = DataLoader(train_data,batch_size=32,shuffle=True)\n",
    "        return dataset\n",
    "    \n",
    "    def val_dataloader(self):\n",
    "        train_data = DataSet_Loader()\n",
    "        dataset = DataLoader(train_data,batch_size=32,shuffle=True)\n",
    "        return dataset\n",
    "    \n",
    "    def validation_step(self, batch,batch_idx):\n",
    "        images,labels = batch\n",
    "        images = images.view(-1,56*56*3)\n",
    "        outputs = self(images)\n",
    "        loss = criterion(outputs,labels)\n",
    "        wandb.log({'Val Loss':loss.item()})\n",
    "        return {'val_loss':loss}\n",
    "    \n",
    "    def configure_optimizers(self):\n",
    "        return torch.optim.Adam(self.parameters(),lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "33ac748b",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.MSELoss()\n",
    "class Model(pl.LightningModule):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.activation = ReLU()\n",
    "        self.linear1 = Linear(3*56*56,256)\n",
    "        self.linear2 = Linear(256,512)\n",
    "        self.linear3 = Linear(512,1024)\n",
    "        self.output = Linear(1024,len(labels))\n",
    "    \n",
    "    def forward(self,X):\n",
    "        preds = self.linear1(X)\n",
    "        preds = self.activation(self.linear2(preds))\n",
    "        preds = self.activation(self.linear3(preds))\n",
    "        preds = self.output(preds)\n",
    "        return preds\n",
    "    \n",
    "    def training_step(self,batch,batch_idx):\n",
    "        images,labels = batch\n",
    "        images = images.view(-1,56*56*3)\n",
    "        outputs = self(images)\n",
    "        loss = criterion(outputs,labels)\n",
    "        wandb.log({'Loss':loss.item()})\n",
    "        return {'train_loss':loss}\n",
    "    \n",
    "    def train_dataloader(self):\n",
    "        train_data = DataSet_Loader()\n",
    "        dataset = DataLoader(train_data,batch_size=32,shuffle=True)\n",
    "        return dataset\n",
    "    \n",
    "    def val_dataloader(self):\n",
    "        train_data = DataSet_Loader()\n",
    "        dataset = DataLoader(train_data,batch_size=32,shuffle=True)\n",
    "        return dataset\n",
    "    \n",
    "    def validation_step(self, batch,batch_idx):\n",
    "        images,labels = batch\n",
    "        images = images.view(-1,56*56*3)\n",
    "        outputs = self(images)\n",
    "        loss = criterion(outputs,labels)\n",
    "        wandb.log({'Val Loss':loss.item()})\n",
    "        return {'val_loss':loss}\n",
    "    \n",
    "    def configure_optimizers(self):\n",
    "        return torch.optim.Adam(self.parameters(),lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f1454541",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "                Tracking run with wandb version 0.12.1<br/>\n",
       "                Syncing run <strong style=\"color:#cdcd00\">baseline</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/ranuga-d/Intel-Image-Classification-Learning-PyTorch-Lightning\" target=\"_blank\">https://wandb.ai/ranuga-d/Intel-Image-Classification-Learning-PyTorch-Lightning</a><br/>\n",
       "                Run page: <a href=\"https://wandb.ai/ranuga-d/Intel-Image-Classification-Learning-PyTorch-Lightning/runs/39gl57q0\" target=\"_blank\">https://wandb.ai/ranuga-d/Intel-Image-Classification-Learning-PyTorch-Lightning/runs/39gl57q0</a><br/>\n",
       "                Run data is saved locally in <code>/home/indika/Programming/Projects/Python/Artifical-Intelligence/PyTorch-Lightning/Intel-Image-Classification-Learning-PyTorch-Lightning/wandb/run-20211015_151150-39gl57q0</code><br/><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "wandb.init(project=PROJECT_NAME,name='baseline')\n",
    "model = Model()\n",
    "trainer = Trainer(125)\n",
    "trainer.fit(model)\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "74f1c073",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.MSELoss()\n",
    "class Model(pl.LightningModule):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.activation = nn.ReLU()\n",
    "        self.linear1 = nn.Linear(3*56*56,256)\n",
    "        self.linear2 = nn.Linear(256,512)\n",
    "        self.linear3 = nn.Linear(512,1024)\n",
    "        self.output = nn.Linear(1024,len(labels))\n",
    "    \n",
    "    def forward(self,X):\n",
    "        preds = self.linear1(X)\n",
    "        preds = self.activation(self.linear2(preds))\n",
    "        preds = self.activation(self.linear3(preds))\n",
    "        preds = self.output(preds)\n",
    "        return preds\n",
    "    \n",
    "    def training_step(self,batch,batch_idx):\n",
    "        images,labels = batch\n",
    "        images = images.view(-1,56*56*3)\n",
    "        outputs = self(images)\n",
    "        loss = criterion(outputs,labels)\n",
    "        wandb.log({'Loss':loss.item()})\n",
    "        return {'train_loss':loss}\n",
    "    \n",
    "    def train_dataloader(self):\n",
    "        train_data = DataSet_Loader()\n",
    "        dataset = DataLoader(train_data,batch_size=32,shuffle=True)\n",
    "        return dataset\n",
    "    \n",
    "    def val_dataloader(self):\n",
    "        train_data = DataSet_Loader()\n",
    "        dataset = DataLoader(train_data,batch_size=32,shuffle=True)\n",
    "        return dataset\n",
    "    \n",
    "    def validation_step(self, batch,batch_idx):\n",
    "        images,labels = batch\n",
    "        images = images.view(-1,56*56*3)\n",
    "        outputs = self(images)\n",
    "        loss = criterion(outputs,labels)\n",
    "        wandb.log({'Val Loss':loss.item()})\n",
    "        return {'val_loss':loss}\n",
    "    \n",
    "    def configure_optimizers(self):\n",
    "        return torch.optim.Adam(self.parameters(),lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "61cdb241",
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.init(project=PROJECT_NAME,name='baseline')\n",
    "model = Model()\n",
    "trainer = Trainer(125)\n",
    "trainer.fit(model)\n",
    "wandb.finish()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
